{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd3faf54-4921-4e7e-9859-1fd8d5133805",
   "metadata": {},
   "source": [
    "# __STRATEGIE D'ANALYSE BIOINFORMATIQUE - MENTORING PROJECT__\n",
    "\n",
    "__AGMIMONHAN Attolou Raoul, NAME Pakyendou Estel__\n",
    "\n",
    "__Tuteurs: Aurore COMTE & Sebastien RAVEL__\n",
    "\n",
    "Jupyter inspired by the model created by C. Tranchant (DIADE-IRD), J. Orjuela (DIADE-IRD), F. Sabot (DIADE-IRD) and A. Dereeper (PHIM-IRD)\n",
    "***\n",
    "\n",
    "# <span style=\"color: #006E7F\">Table of contents</span>\n",
    "<a class=\"anchor\" id=\"home\"></a>\n",
    "\n",
    "\n",
    "[PRACTICE V - PCA - DAPC - OTHERS](#Genetic_dversity)\n",
    "\n",
    "   \n",
    "   \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72edcf4-4408-4359-bf5d-ff972f68a584",
   "metadata": {},
   "source": [
    "# __Practice V__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fb44d8-7946-433f-a37b-b69dc229c2c3",
   "metadata": {},
   "source": [
    "## Evaluate level of missing data (by sample, by positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9aaeb8-d11b-4a34-b49a-9586a71f73f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Créer un répertoire PLINK dans le repertoire de travail\n",
    "\n",
    "mkdir -p /scratch/MOryzae/PLINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bc9fea-251d-4427-8080-51803aed278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se déplacer dans le répertoire créé\n",
    "\n",
    "cd PLINK/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a2d872-6eb4-40c6-baed-0c10999e2514",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Charger le module plink avant tout\n",
    "\n",
    "module load plink/1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a48770b-2811-4b02-bce7-905e781928e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lancer l'évaluation des données manquantes\n",
    "\n",
    "plink -vcf /scratch/MOryzae/SNP/vcf_files/snp_correct.vcf.gz --allow-extra-chr --missing --out  ./plink/dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f3ea6754-ba12-4a59-a63a-40540459a1e0",
   "metadata": {},
   "source": [
    "Pipeline pour réaliser une PCA et une DAPC sur des fichiers VCF après un SNP calling\n",
    "\n",
    "Ce guide inclut les commandes exactes à exécuter avec des outils complémentaires comme vcftools, bcftools, plink, et des packages R comme SNPRelate et adegenet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac787be-83d0-49e3-ad02-df0e777c0726",
   "metadata": {},
   "source": [
    "## __Generate PCA using genotyping information contained in VCF__"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87ff70a3-a24b-47bd-897b-121dacb779c1",
   "metadata": {},
   "source": [
    "Plink alllows to create a PCA (principal components analysis) of samples, so that we can easily evaluate genetic distance between samples.\n",
    "\n",
    "This will generate a matrix of coordinates in the different component. By default, it provides the first 20 principal components of the variance-standardized relationship matrix. We will focus only the first 3 axes for subsequent visualization (--pca 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c37952-2377-46a4-af4e-ce1d1bd72b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lancer le run\n",
    "\n",
    "plink -vcf /scratch/MOryzae/SNP/vcf_files/snp_correct.vcf.gz --allow-extra-chr --cluster --matrix --pca 3 --mind --out ./plink/dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428b4505-1651-47bb-b10d-843d49c98263",
   "metadata": {},
   "source": [
    "## __Convertissons le fichier \"eigenvec\" généré en format csv__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91b58bf-9592-4493-88ed-3345174a0ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se déplacer dans le répertoire créé\n",
    "\n",
    "cd /scratch/MOryzae/SCRIPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4160ecc8-3d7e-42b5-908a-82fccdeb899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ouvrir l'éditeur de texte nano\n",
    "\n",
    "nano eigenvec_to_csv.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce6b0e-b711-493c-a3fd-d539d2193779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "############# SLURM Configuration ##############\n",
    "\n",
    "### Define Job name\n",
    "#SBATCH --job-name=eigenvec_to_csv\n",
    "\n",
    "### Define partition to use\n",
    "#SBATCH -p normal\n",
    "\n",
    "### Define number of CPUs to use\n",
    "#SBATCH -c 8\n",
    "\n",
    "### Specify the node to run on\n",
    "#SBATCH --nodelist=node20  # Run the job on node20\n",
    "\n",
    "#################################################\n",
    "\n",
    "########### Execution Command ###################\n",
    "\n",
    "# Define directories\n",
    "INPUT_DIR=\"/scratch/MOryzae/PLINK\"\n",
    "OUTPUT_DIR=\"/scratch/MOryzae/PLINK\"\n",
    "\n",
    "# List of directories to process\n",
    "DIRECTORIES=(\"plink\")\n",
    "\n",
    "# Loop through each directory\n",
    "for DIR in \"${DIRECTORIES[@]}\"; do\n",
    "    PCA_FILE=\"$INPUT_DIR/$DIR/dataset.eigenvec\"\n",
    "    OUTPUT_CSV=\"$OUTPUT_DIR/$DIR/dataset.csv\"\n",
    "\n",
    "    # Check if PCA results exist\n",
    "    if [ -f \"$PCA_FILE\" ]; then\n",
    "        echo \"Processing PCA results for $DIR...\"\n",
    "\n",
    "        # Convert eigenvec file to CSV format\n",
    "        awk 'NR==1{print \"FID,IID,PC1,PC2,PC3\"} NR>1{print $1\",\"$2\",\"$3\",\"$4\",\"$5}' \"$PCA_FILE\" > \"$OUTPUT_CSV\"\n",
    "\n",
    "        # Check if conversion was successful\n",
    "        if [ $? -eq 0 ]; then\n",
    "            echo \"Conversion successful: $OUTPUT_CSV created.\"\n",
    "        else\n",
    "            echo \"Error: Failed to convert $PCA_FILE to CSV.\"\n",
    "            exit 1\n",
    "        fi\n",
    "    else\n",
    "        echo \"Error: PCA results file not found in $DIR.\"\n",
    "        exit 1\n",
    "    fi\n",
    "done\n",
    "\n",
    "echo \"PCA analysis completed. Results are saved in $OUTPUT_DIR.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229d069d-328d-4d1f-8990-107624012466",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lancer le script\n",
    "\n",
    "sbash eigenvec_to_csv.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73470799-6c4e-4e3e-9ce0-53ed35e10520",
   "metadata": {},
   "source": [
    "## __Sortir un plot pour la PCA afin de faciliter la visualisation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b6add-a998-4d53-a054-2215d8d56ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ouvrir l'éditeur de texte nano\n",
    "\n",
    "nano pca_plot.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a2b60-4344-4609-bc2b-7958ce00e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "############# SLURM Configuration ##############\n",
    "\n",
    "### Define Job name\n",
    "#SBATCH --job-name=genome_pca_plot\n",
    "\n",
    "### Define partition to use\n",
    "#SBATCH -p normal\n",
    "\n",
    "### Define number of CPUs to use\n",
    "#SBATCH -c 8\n",
    "\n",
    "### Specify the node to run on\n",
    "#SBATCH --nodelist=node20\n",
    "\n",
    "#################################################\n",
    "\n",
    "########### Execution Command ###################\n",
    "\n",
    "module load python/3.12.0  # Charge Python 3.12 sur le cluster\n",
    "\n",
    "# Define directories\n",
    "PCA_RESULTS_DIR=\"/scratch/MOryzae/PLINK\"\n",
    "OUTPUT_PLOT_DIR=\"/scratch/MOryzae/PLINK\"\n",
    "\n",
    "# List of directories to process\n",
    "DIRECTORIES=(\"plink\")\n",
    "\n",
    "# Loop through each directory\n",
    "for DIRECTORY in \"${DIRECTORIES[@]}\"; do\n",
    "    PCA_FILE=\"$PCA_RESULTS_DIR/$DIRECTORY/dataset.eigenvec\"\n",
    "    OUTPUT_DIR=\"$OUTPUT_PLOT_DIR/$DIRECTORY\"\n",
    "    OUTPUT_PLOT_2D=\"$OUTPUT_DIR/dataset_2D.png\"\n",
    "    OUTPUT_PLOT_3D=\"$OUTPUT_DIR/dataset_3D.png\"\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    mkdir -p \"$OUTPUT_DIR\"\n",
    "\n",
    "    # Check if the PCA results file exists\n",
    "    if [ -f \"$PCA_FILE\" ]; then\n",
    "        echo \"Processing PCA results for $DIRECTORY...\"\n",
    "        \n",
    "        # Call the Python script to generate the plots\n",
    "        python3 <<EOF\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os\n",
    "\n",
    "# Define input and output paths\n",
    "pca_results_file = \"$PCA_FILE\"\n",
    "output_plot_2D = \"$OUTPUT_PLOT_2D\"\n",
    "output_plot_3D = \"$OUTPUT_PLOT_3D\"\n",
    "\n",
    "# Read PCA results\n",
    "try:\n",
    "    pca_results = pd.read_csv(pca_results_file, sep=r'\\s+', header=None)\n",
    "    pca_results.columns = ['FID', 'IID', 'PC1', 'PC2', 'PC3']\n",
    "except Exception as e:\n",
    "    print(f\"Error reading PCA results file {pca_results_file}: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Plot 2D scatter plot for PC1 vs PC2\n",
    "try:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(pca_results['PC1'], pca_results['PC2'], s=100)\n",
    "    plt.title('PCA Results: $DIRECTORY (2D)')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.grid()\n",
    "    plt.savefig(output_plot_2D)\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"Error creating 2D plot for {pca_results_file}: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Plot 3D scatter plot for PC1, PC2, and PC3\n",
    "try:\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    scatter = ax.scatter(pca_results['PC1'], pca_results['PC2'], pca_results['PC3'], s=100, c='blue', alpha=0.7)\n",
    "    ax.set_title('PCA Results: $DIRECTORY (3D)')\n",
    "    ax.set_xlabel('Principal Component 1')\n",
    "    ax.set_ylabel('Principal Component 2')\n",
    "    ax.set_zlabel('Principal Component 3')\n",
    "    plt.savefig(output_plot_3D)\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"Error creating 3D plot for {pca_results_file}: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Verify plots were created\n",
    "if not os.path.exists(output_plot_2D) or not os.path.exists(output_plot_3D):\n",
    "    print(f\"Error: Output plots not created for {pca_results_file}\")\n",
    "    exit(1)\n",
    "EOF\n",
    "\n",
    "        # Check if the Python script executed successfully\n",
    "        if [ $? -eq 0 ]; then\n",
    "            echo \"Plots successfully created for $DIRECTORY: $OUTPUT_PLOT_2D, $OUTPUT_PLOT_3D\"\n",
    "        else\n",
    "            echo \"Error: Failed to create plots for $DIRECTORY.\"\n",
    "            exit 1\n",
    "        fi\n",
    "    else\n",
    "        echo \"Error: PCA results file not found in $DIRECTORY.\"\n",
    "        exit 1\n",
    "    fi\n",
    "done\n",
    "\n",
    "echo \"All PCA plots created successfully.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7915d9d0-c10a-4c72-840a-7a0fe162bbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lancer le script\n",
    "\n",
    "sbash pca_plot.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98daa7d7-7c41-4100-b9d5-cb07e88e27ef",
   "metadata": {},
   "source": [
    "Utilisons des outils afin d'interprêter les résultats de la PCA ou les plots obtenus\n",
    "\n",
    "    Pour celà, nous disposons de trois outils fréquemment utilisés"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4069b7c7-770e-4e09-bfa6-d5ee862cf026",
   "metadata": {},
   "source": [
    "Résumé\n",
    "\n",
    "    Utilisez k-means pour partitionner les données en supposant un nombre de clusters.\n",
    "    Appliquez DBSCAN pour détecter les clusters denses et identifier des outliers.\n",
    "    Utilisez la méthode du coude et l’indice de silhouette pour déterminer le nombre optimal de clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464faebe-1271-455d-a105-edd0a3542233",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se déplacer dans le répertoire créé\n",
    "\n",
    "cd /scratch/MOryzae/SCRIPTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c61d355-2244-453f-bbf2-fe74e427e33a",
   "metadata": {},
   "source": [
    "Sauvegarder le script python dans le répertoire SCRIPTS avant le script sbatch\n",
    "\n",
    "Le script sbatch va alors utiliser le contenu du script python pour l'exécution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719a0261-16d1-4637-b0c5-2a3b3bdab639",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ouvrir l'éditeur de texte nano\n",
    "\n",
    "nano clustering_analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e6d5ad-bb07-41cc-90ab-adda2bbc89a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Check for input arguments\n",
    "if len(sys.argv) != 3:\n",
    "    print(\"Usage: python clustering_analysis.py <PCA_FILE> <OUTPUT_DIR>\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Input and output paths\n",
    "pca_file = sys.argv[1]\n",
    "output_dir = sys.argv[2]\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load PCA data\n",
    "try:\n",
    "    print(f\"Loading PCA data from {pca_file}...\")\n",
    "    data = pd.read_csv(pca_file, sep=r'\\s+', header=None)\n",
    "    data.columns = ['FID', 'IID', 'PC1', 'PC2', 'PC3']\n",
    "    X = data[['PC1', 'PC2', 'PC3']]\n",
    "except Exception as e:\n",
    "    print(f\"Error loading PCA data: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Determine optimal number of clusters using the elbow method\n",
    "print(\"Calculating optimal number of clusters (Elbow Method)...\")\n",
    "inertia = []\n",
    "k_values = range(1, 10)\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "    kmeans.fit(X)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_values, inertia, marker='o')\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "elbow_plot_path = os.path.join(output_dir, 'elbow_method.png')\n",
    "plt.savefig(elbow_plot_path)\n",
    "print(f\"Elbow Method plot saved to {elbow_plot_path}\")\n",
    "\n",
    "# Apply k-means clustering with k=3 (or adjust based on elbow results)\n",
    "print(\"Applying k-means clustering...\")\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init='auto')\n",
    "data['Cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Sauvegarder les résultats avec les clusters dans un fichier CSV\n",
    "output_csv = os.path.join(output_dir, 'clustered_data.csv')\n",
    "data.to_csv(output_csv, index=False)\n",
    "print(f\"Données annotées avec clusters sauvegardées dans {output_csv}\")\n",
    "\n",
    "\n",
    "# Visualize k-means clusters in 3D\n",
    "print(\"Generating 3D k-means plot...\")\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(data['PC1'], data['PC2'], data['PC3'], c=data['Cluster'], cmap='viridis', s=100)\n",
    "plt.colorbar(scatter, ax=ax)\n",
    "ax.set_title('k-means Clustering (k=3)')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "kmeans_plot_path = os.path.join(output_dir, 'kmeans_pca_plot_3d.png')\n",
    "plt.savefig(kmeans_plot_path)\n",
    "print(f\"3D k-means plot saved to {kmeans_plot_path}\")\n",
    "\n",
    "# Apply DBSCAN clustering\n",
    "print(\"Applying DBSCAN clustering...\")\n",
    "dbscan = DBSCAN(eps=0.1, min_samples=3)\n",
    "data['DBSCAN_Cluster'] = dbscan.fit_predict(X)\n",
    "\n",
    "# Visualize DBSCAN clusters in 3D\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(data['PC1'], data['PC2'], data['PC3'], c=data['DBSCAN_Cluster'], cmap='plasma', s=100)\n",
    "plt.colorbar(scatter, ax=ax)\n",
    "ax.set_title('DBSCAN Clustering')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "dbscan_plot_path = os.path.join(output_dir, 'dbscan_pca_plot_3d.png')\n",
    "plt.savefig(dbscan_plot_path)\n",
    "print(f\"3D DBSCAN plot saved to {dbscan_plot_path}\")\n",
    "\n",
    "# Calculate silhouette scores for different k\n",
    "print(\"Calculating silhouette scores...\")\n",
    "silhouette_scores = []\n",
    "for k in range(2, 10):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    silhouette_scores.append(silhouette_score(X, labels))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(2, 10), silhouette_scores, marker='o')\n",
    "plt.title('Silhouette Scores')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "silhouette_plot_path = os.path.join(output_dir, 'silhouette_scores.png')\n",
    "plt.savefig(silhouette_plot_path)\n",
    "print(f\"Silhouette Scores plot saved to {silhouette_plot_path}\")\n",
    "\n",
    "print(\"Clustering analysis completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27ca31c-f800-4ee6-8940-bbc89c564384",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ouvrir l'éditeur de texte nano\n",
    "\n",
    "nano pca_learning.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa769f3-286d-448d-98b0-53cace57bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "############# SLURM Configuration ##############\n",
    "#SBATCH --job-name=pca_learning\n",
    "#SBATCH -p normal\n",
    "#SBATCH -c 8\n",
    "#SBATCH --nodelist=node20\n",
    "\n",
    "#################################################\n",
    "\n",
    "# Load necessary modules\n",
    "module load python/3.12.0\n",
    "\n",
    "# Define directories\n",
    "PCA_RESULTS_DIR=\"/scratch/MOryzae/PLINK\"\n",
    "OUTPUT_PLOT_DIR=\"/scratch/MOryzae/PLINK/PCA\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "mkdir -p \"$OUTPUT_PLOT_DIR\"\n",
    "\n",
    "# List of subdirectories to process\n",
    "DIRECTORIES=(\"plink\")\n",
    "\n",
    "# Loop over each directory\n",
    "for DIRECTORY in \"${DIRECTORIES[@]}\"; do\n",
    "    PCA_FILE=\"$PCA_RESULTS_DIR/$DIRECTORY/dataset.eigenvec\"\n",
    "    OUTPUT_DIR=\"$OUTPUT_PLOT_DIR\"\n",
    "\n",
    "    # Check if the PCA file exists\n",
    "    if [[ -f \"$PCA_FILE\" ]]; then\n",
    "        mkdir -p \"$OUTPUT_DIR\"\n",
    "        echo \"Processing PCA file: $PCA_FILE\"\n",
    "\n",
    "        # Run the Python script for clustering and plotting\n",
    "        python3 clustering_analysis.py \"$PCA_FILE\" \"$OUTPUT_DIR\"\n",
    "\n",
    "        echo \"Processing completed for directory: $DIRECTORY\"\n",
    "    else\n",
    "        echo \"PCA file not found: $PCA_FILE\"\n",
    "    fi\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11069769-cd16-4678-a99c-ce36b83d84a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lancer le script\n",
    "\n",
    "sbash pca_learning.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a0516e-97fd-44f3-8105-a0fa2d23966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Copier les données vers le NAS\n",
    "\n",
    "scp -r /scratch/MOryzae/PLINK/ san:/projects/medium/CIBiG_MOryzae/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69421ed3-3189-4a27-a230-9e8236a1dfa3",
   "metadata": {},
   "source": [
    "#### Analyser les plots produits et interprêter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092f8ce9-9021-41b5-a0f8-c203dc36c2ba",
   "metadata": {},
   "source": [
    "## __DAPC__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dab57e-9a2c-413b-902d-307617fad204",
   "metadata": {},
   "source": [
    "Lancer ces scripts R sur votre machine locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c8870d-8cae-4879-9611-801b7a16e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ouvrir l'éditeur de texte nano\n",
    "\n",
    "nano dapc_analysis.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89329f32-3849-4505-8c4e-14c950c82ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les bibliothèques nécessaires\n",
    "if (!requireNamespace(\"adegenet\")) install.packages(\"adegenet\")\n",
    "if (!requireNamespace(\"factoextra\")) install.packages(\"factoextra\") # Pour le clustering\n",
    "if (!requireNamespace(\"ggplot2\")) install.packages(\"ggplot2\")\n",
    "if (!requireNamespace(\"dplyr\")) install.packages(\"dplyr\")\n",
    "\n",
    "library(adegenet)\n",
    "library(factoextra)\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "\n",
    "# Définir les chemins d'entrée et de sortie\n",
    "input_file <- \"/home/name/Documents/Projet_CIBiG/Mentoring_Project/Results/PLINK/plink/dataset.eigenvec\"\n",
    "output_dir <- \"/home/name/Documents/Projet_CIBiG/Mentoring_Project/Results/PLINK/DAPC\"\n",
    "\n",
    "# Créer le répertoire de sortie si nécessaire\n",
    "if (!dir.exists(output_dir)) {\n",
    "  dir.create(output_dir, recursive = TRUE)\n",
    "  cat(\"Répertoire de sortie créé :\", output_dir, \"\\n\")\n",
    "}\n",
    "\n",
    "# Charger les données PCA\n",
    "cat(\"Chargement des données PCA...\\n\")\n",
    "pca_data <- read.table(input_file, header = FALSE)\n",
    "colnames(pca_data) <- c(\"FID\", \"IID\", \"PC1\", \"PC2\", \"PC3\")  # Modifier selon vos colonnes\n",
    "X <- pca_data %>% select(PC1, PC2, PC3)\n",
    "\n",
    "# Étape 1 : Clustering des individus (k-means)\n",
    "cat(\"Application de k-means pour générer des groupes...\\n\")\n",
    "set.seed(42)  # Pour assurer la reproductibilité\n",
    "n_clusters <- 3  # Ajustez selon vos besoins ou utilisez la méthode du coude (voir ci-dessous)\n",
    "kmeans_result <- kmeans(X, centers = n_clusters)\n",
    "\n",
    "# Ajouter les groupes au jeu de données\n",
    "pca_data$Group <- as.factor(kmeans_result$cluster)\n",
    "\n",
    "# Sauvegarder les groupes dans un fichier CSV\n",
    "groups_file <- file.path(output_dir, \"groups_kmeans.csv\")\n",
    "write.csv(pca_data, groups_file, row.names = FALSE)\n",
    "cat(\"Groupes sauvegardés dans :\", groups_file, \"\\n\")\n",
    "\n",
    "# Étape optionnelle : Déterminer le nombre optimal de clusters\n",
    "# Méthode du coude\n",
    "cat(\"Déterminer le nombre optimal de clusters avec la méthode du coude...\\n\")\n",
    "fviz_nbclust(X, kmeans, method = \"wss\") +\n",
    "  labs(title = \"Méthode du coude pour déterminer k\")\n",
    "\n",
    "# Étape 2 : DAPC\n",
    "cat(\"Optimisation du nombre de PCs pour DAPC...\\n\")\n",
    "dapc_initial <- dapc(X, pca_data$Group)\n",
    "optimal_pcs <- optim.a.score(dapc_initial)\n",
    "n_pcs <- optimal_pcs$n.pca\n",
    "cat(paste(\"Nombre optimal de PCs :\", n_pcs, \"\\n\"))\n",
    "\n",
    "# Réaliser la DAPC avec le nombre optimal de PCs\n",
    "dapc_result <- dapc(X, pca_data$Group, n.pca = n_pcs)\n",
    "\n",
    "# Étape 3 : Visualisation des résultats\n",
    "cat(\"Génération du graphique des clusters DAPC...\\n\")\n",
    "scatter_file <- file.path(output_dir, \"dapc_scatter.png\")\n",
    "png(scatter_file, width = 800, height = 600)\n",
    "scatter(dapc_result, scree.da = TRUE, posi.da = \"bottomleft\", scree.pca = TRUE)\n",
    "dev.off()\n",
    "cat(\"Graphique DAPC sauvegardé dans :\", scatter_file, \"\\n\")\n",
    "\n",
    "# Graphique ggplot des clusters\n",
    "dapc_df <- data.frame(dapc_result$ind.coord) %>%\n",
    "  mutate(Group = pca_data$Group)  # Ajouter les groupes au dataframe\n",
    "\n",
    "ggplot_file <- file.path(output_dir, \"dapc_ggplot.png\")\n",
    "gg <- ggplot(dapc_df, aes(x = LD1, y = LD2, color = Group)) +\n",
    "  geom_point(size = 3, alpha = 0.8) +\n",
    "  theme_minimal() +\n",
    "  labs(title = \"Clusters DAPC\", x = \"Discriminant Axis 1\", y = \"Discriminant Axis 2\")\n",
    "ggsave(ggplot_file, plot = gg, width = 8, height = 6)\n",
    "cat(\"Graphique ggplot DAPC sauvegardé dans :\", ggplot_file, \"\\n\")\n",
    "\n",
    "# Étape 4 : Contributions des variables\n",
    "cat(\"Visualisation des contributions des variables...\\n\")\n",
    "loading_file <- file.path(output_dir, \"dapc_loadings.png\")\n",
    "png(loading_file, width = 800, height = 600)\n",
    "loadingplot(dapc_result$var.contr, axis = 1, threshold = 0.005, lab.jitter = 1)\n",
    "dev.off()\n",
    "cat(\"Graphique des contributions sauvegardé dans :\", loading_file, \"\\n\")\n",
    "\n",
    "# Étape 5 : Sauvegarder les résultats\n",
    "results_file <- file.path(output_dir, \"dapc_results_with_clusters.csv\")\n",
    "write.csv(dapc_df, results_file, row.names = FALSE)\n",
    "cat(\"Résultats DAPC sauvegardés dans :\", results_file, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f63e5d-20ce-4a71-9d26-96a144197e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "source(\"/path/to/working dorectory/on your laptop/dapc_analysis.R\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
